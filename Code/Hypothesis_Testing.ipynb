{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "\n",
    "df = pd.read_csv('../Datasets/data_without_normalization.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Comparing the Distributions of URL Lengths between Fake vs Real URLS. (Using Paired T-Test)\n",
    "\n",
    "Null Hypothesis : There is no difference in means of distributions of fake vs real URLs.\n",
    "\n",
    "Alternative Hypothesis : There is a difference in means of distributions of fake vs real URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test statistic: -37.76386453569706\n",
      "Critical value: 1.9604386466615242\n",
      "Reject the null hypothesis: There is a significant difference between the means.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel, t\n",
    "\n",
    "# Separating the fake samples from legitimate samples.\n",
    "legitimate_df = df[df['label'] == 1]\n",
    "fake_df = df[df['label'] == 0]\n",
    "\n",
    "# Randomly sampling 5000 of each class.\n",
    "sampled_legitimate_df = legitimate_df.sample(n = 5000, replace = False, random_state = 42)\n",
    "sampled_fake_df = fake_df.sample(n = 5000, random_state = 42, replace = False)\n",
    "\n",
    "legitimate_data = sampled_legitimate_df['URLLength'].to_numpy()\n",
    "fake_data = sampled_fake_df['URLLength'].to_numpy()\n",
    "\n",
    "# Performing the test.\n",
    "t_statistic, p_value = ttest_rel(legitimate_data, fake_data)\n",
    "print(\"test statistic:\", t_statistic)\n",
    "\n",
    "# Using 5% as our significance level.\n",
    "alpha = 0.05\n",
    "\n",
    "# Finding critical value for double-sided t-test.\n",
    "deg_free = 4999\n",
    "critical_value = t.ppf(1 - alpha/2, deg_free)\n",
    "print(\"Critical value:\", critical_value)\n",
    "\n",
    "if t_statistic <= critical_value and t_statistic >= (-1) * critical_value:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the means.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the means.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since test statistic is -ve, the fake URLs have significantly larger URL length.\n",
    "\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2 : Checking if there is a linear relationship between number of digits and letters in a URL.\n",
    "\n",
    "Null Hypothesis : There isn't a linear relationship.\n",
    "\n",
    "Alternative Hypothesis : There is a linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient (r): 0.46966500257238347\n",
      "t-statistic: 53.193730152631524\n",
      "Critical value 1.9602012873568364\n",
      "Reject the null hypothesis: Correlation is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Randomly sample 10000 data points.\n",
    "sampled_df = df.sample(n = 10000, replace = False, random_state = 42)\n",
    "\n",
    "letter_data = sampled_df['NoOfLettersInURL'].to_numpy()\n",
    "digit_data = sampled_df['NoOfDegitsInURL'].to_numpy()\n",
    "\n",
    "r, p_value = pearsonr(letter_data, digit_data)\n",
    "\n",
    "# Calculating the test statistics\n",
    "n = 10000\n",
    "t_statistic = r * np.sqrt((n - 2) / (1 - r**2))\n",
    "\n",
    "# Using 5% significance level.\n",
    "alpha = 0.05\n",
    "deg_free = n - 2\n",
    "critical_value = t.ppf(1 - alpha / 2, deg_free)\n",
    "\n",
    "print(\"Correlation coefficient (r):\", r)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"Critical value\", critical_value)\n",
    "\n",
    "if abs(t_statistic) > critical_value:\n",
    "    print(\"Reject the null hypothesis: Correlation is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: Correlation is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there is a linear relationship between number of digits and letter in a URL. They are positively correlated.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3 : Checking if there is a linear relationship between URL length and Domain Length.\n",
    "\n",
    "Null Hypothesis : There isn't a linear relationship.\n",
    "\n",
    "Alternative Hypothesis : There is a linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient (r): 0.4411837264473263\n",
      "t-statistic: 49.156601933693764\n",
      "Critical value 1.9602012873568364\n",
      "Reject the null hypothesis: Correlation is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 10000 data points.\n",
    "sampled_df = df.sample(n = 10000, replace = False, random_state = 44)\n",
    "\n",
    "url_data = sampled_df['URLLength'].to_numpy()\n",
    "domain_data = sampled_df['DomainLength'].to_numpy()\n",
    "\n",
    "r, p_value = pearsonr(url_data, domain_data)\n",
    "\n",
    "# Calculating the test statistics\n",
    "n = 10000\n",
    "t_statistic = r * np.sqrt((n - 2) / (1 - r**2))\n",
    "\n",
    "# Using 5% significance level.\n",
    "alpha = 0.05\n",
    "deg_free = n - 2\n",
    "critical_value = t.ppf(1 - alpha / 2, deg_free)\n",
    "\n",
    "print(\"Correlation coefficient (r):\", r)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"Critical value\", critical_value)\n",
    "\n",
    "if abs(t_statistic) > critical_value:\n",
    "    print(\"Reject the null hypothesis: Correlation is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: Correlation is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there is a linear relationship between the URL and Domain Length. They are positively correlated.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 4 : Checking if there is a relationship between having a title and the URL being fake or real.\n",
    "\n",
    "Null Hypothesis : They are independent.\n",
    "\n",
    "Alternative Hypothesis : They are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:\n",
      " label        0     1\n",
      "HasTitle            \n",
      "0         1611     8\n",
      "1         3372  5009\n",
      "\n",
      "Chi-squared Statistic: 1904.4377424094232\n",
      "Degrees of Freedom: 1\n",
      "\n",
      "Critical value for chi-squared distribution:\n",
      "Left: 0.0009820691171752557    Right: 5.023886187314888\n",
      "Reject the null hypothesis: There is a significant association between the variables.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats  as stats\n",
    "\n",
    "# Randomly sample 10000 data points.\n",
    "sampled_df = df.sample(n = 10000, replace = False, random_state = 43)\n",
    "\n",
    "# Creating the table\n",
    "table = pd.crosstab(sampled_df['HasTitle'], sampled_df['label'])\n",
    "print(\"Table:\\n\", table)\n",
    "\n",
    "# Performing the test.\n",
    "chi2, p, deg_free, expected_freq = stats.chi2_contingency(table)\n",
    "\n",
    "print(\"\\nChi-squared Statistic:\", chi2)\n",
    "print(\"Degrees of Freedom:\", deg_free)\n",
    "\n",
    "# Using 5% level of significance.\n",
    "alpha = 0.05\n",
    "\n",
    "# Finding critical value\n",
    "critical_value_right = stats.chi2.ppf(1 - alpha/2, deg_free)\n",
    "critical_value_left = stats.chi2.ppf(alpha/2, deg_free)\n",
    "\n",
    "print(f\"\\nCritical value for chi-squared distribution:\\nLeft: {critical_value_left}    Right: {critical_value_right}\")\n",
    "\n",
    "if chi2 > critical_value_right or chi2 < critical_value_left:\n",
    "    print(\"Reject the null hypothesis: There is a significant association between the variables.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant association between the variables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the properties of 'having a title' and 'being a fake or real URL' are dependent.\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 5 : Checking if there is a relationship between being a HTTPS link and the URL being fake or real.\n",
    "\n",
    "Null Hypothesis : They are independent.\n",
    "\n",
    "Alternative Hypothesis : They are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:\n",
      " label       0     1\n",
      "IsHTTPS            \n",
      "0        2577     0\n",
      "1        2316  5107\n",
      "\n",
      "Chi-squared Statistic: 3620.725035244844\n",
      "Degrees of Freedom: 1\n",
      "\n",
      "Critical value for chi-squared distribution:\n",
      "Left: 0.0009820691171752557    Right: 5.023886187314888\n",
      "Reject the null hypothesis: There is a significant association between the variables.\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 10000 data points.\n",
    "sampled_df = df.sample(n = 10000, replace = False, random_state = 45)\n",
    "\n",
    "# Creating the table\n",
    "table = pd.crosstab(sampled_df['IsHTTPS'], sampled_df['label'])\n",
    "print(\"Table:\\n\", table)\n",
    "\n",
    "# Performing the test.\n",
    "chi2, p, deg_free, expected_freq = stats.chi2_contingency(table)\n",
    "\n",
    "print(\"\\nChi-squared Statistic:\", chi2)\n",
    "print(\"Degrees of Freedom:\", deg_free)\n",
    "\n",
    "# Using 5% level of significance.\n",
    "alpha = 0.05\n",
    "\n",
    "# Finding critical value\n",
    "critical_value_right = stats.chi2.ppf(1 - alpha/2, deg_free)\n",
    "critical_value_left = stats.chi2.ppf(alpha/2, deg_free)\n",
    "\n",
    "print(f\"\\nCritical value for chi-squared distribution:\\nLeft: {critical_value_left}    Right: {critical_value_right}\")\n",
    "\n",
    "if chi2 > critical_value_right or chi2 < critical_value_left:\n",
    "    print(\"Reject the null hypothesis: There is a significant association between the variables.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant association between the variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties of 'being a HTTPS URL' and 'being a fake/legitimate URL' are dependent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
